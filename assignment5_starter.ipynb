{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KNN class\n",
    "class KNN:\n",
    "    def __init__(self, k, distance_metric):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X, dtype=float)  # Ensure float type\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def predictTrain(self, X):\n",
    "        X = np.array(X, dtype=float)  # Ensure float type\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = self.compute_distance(self.X_train, x)\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = self.y_train[k_indices]\n",
    "\n",
    "            # Manual mode calculation\n",
    "            unique_labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "            most_common_label = unique_labels[np.argmax(counts)]\n",
    "            predictions.append(most_common_label)\n",
    "\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def predictTest(self, X):\n",
    "        # Predict probabilities for each sample in X\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        return np.array([self._predictTest(x) for x in X])\n",
    "    \n",
    "    def _predictTest(self, x):\n",
    "        distances = self.compute_distance(self.X_train, x)\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        k_nearest_distances = distances[k_indices]\n",
    "        weights = 1 / (k_nearest_distances + 1e-10)\n",
    "        weighted_sum = np.sum(weights * k_nearest_labels)\n",
    "        total_weight = np.sum(weights)\n",
    "        prob = weighted_sum / total_weight\n",
    "        return prob\n",
    "\n",
    "    def compute_distance(self, X1, X2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((X1 - X2) ** 2, axis=1))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(X1 - X2), axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data preprocessing function\n",
    "def preprocess_data(train_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "\n",
    "    # TODO: Implement data preprocessing\n",
    "    # Handle categorical variables, scale features, etc.\n",
    "    \n",
    "     # Handle missing values (if necessary) - here, just dropping rows with missing values\n",
    "    train_data = train_data.dropna()\n",
    "    test_data = test_data.dropna()\n",
    "\n",
    "    #changes for gender \n",
    "    train_data['Gender'] = train_data['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    test_data['Gender'] = test_data['Gender'].map({'Male': 1, 'Female': 0})   \n",
    "    #changes for geograpy\n",
    "    geography_map = {category: idx for idx, category in enumerate(train_data['Geography'].unique())}\n",
    "    train_data['Geography'] = train_data['Geography'].map(geography_map)\n",
    "    test_data['Geography'] = test_data['Geography'].map(geography_map)\n",
    "\n",
    "\n",
    "    ###Feature Enginneering\n",
    "\n",
    "    ###interaction terms first\n",
    "\n",
    "    train_data['Balance_Salary_Ratio'] = train_data['Balance'] / (train_data['EstimatedSalary'] + 1e-10)\n",
    "    test_data['Balance_Salary_Ratio'] = test_data['Balance'] / (test_data['EstimatedSalary'] + 1e-10)\n",
    "\n",
    "    train_data['Age_Tenure_Ratio'] = train_data['Age'] / (train_data['Tenure'] + 1e-10)  \n",
    "    test_data['Age_Tenure_Ratio'] = test_data['Age'] / (test_data['Tenure'] + 1e-10)  \n",
    "\n",
    "\n",
    "    #Make a group for age\n",
    "    train_data['AgeGroup'] = pd.cut(train_data['Age'], bins=[0, 29, 37, 45, 100], labels=[0, 1, 2, 3]).astype(int)\n",
    "    test_data['AgeGroup'] = pd.cut(test_data['Age'], bins=[0, 29, 37, 45, 100], labels=[0, 1, 2, 3]).astype(int)\n",
    "    \n",
    "    #Make a group for Tenure\n",
    "    train_data['TenureGroup'] = pd.cut(train_data['Tenure'], bins = [-1, 1, 3, 8, 12, 20], labels = [0, 1, 2, 3, 4]).astype(int)\n",
    "    test_data['TenureGroup'] = pd.cut(test_data['Tenure'], bins = [-1, 1, 3, 8, 12, 20], labels = [0, 1, 2, 3, 4]).astype(int)\n",
    "    \n",
    "    # #Make a group for Balance\n",
    "    train_data['BalanceGroup'] = pd.cut(train_data['Balance'], bins=[-1, 20000, 50000, 100000, 150000, 100000000],labels=[0, 1, 2, 3, 4]).astype(int)\n",
    "    test_data['BalanceGroup'] = pd.cut(test_data['Balance'], bins=[-1, 20000, 50000, 100000, 150000, 100000000],labels=[0, 1, 2, 3, 4]).astype(int)\n",
    "    \n",
    "    train_data['CreditScoreGroup'] = pd.cut(train_data['CreditScore'], bins=[430, 550, 650, 750, 850], labels=[0, 1, 2, 3]).astype(int)\n",
    "    test_data['CreditScoreGroup'] = pd.cut(test_data['CreditScore'], bins=[430, 550, 650, 750, 850], labels=[0, 1, 2, 3]).astype(int)\n",
    "\n",
    "    \n",
    "\n",
    "    ## Dropping Group Columns not Age \n",
    "    train_data.drop(columns='Tenure', inplace=True)\n",
    "    test_data.drop(columns='Tenure', inplace=True)\n",
    "    train_data.drop(columns='Balance', inplace=True)\n",
    "    test_data.drop(columns='Balance', inplace=True)\n",
    "\n",
    "    X_train = train_data.drop(columns=['id', 'CustomerId', 'Surname', 'Exited'])  # Drop unnecessary columns\n",
    "    y_train = train_data['Exited']\n",
    "    X_test = test_data.drop(columns=['id', 'CustomerId', 'Surname'])\n",
    "\n",
    "    # #doing a min/max scaler \n",
    "    # X_train_scaled = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "    # X_test_scaled = (X_test - X_train.min()) / (X_train.max() - X_train.min())\n",
    "\n",
    "    #standard scaler\n",
    "    X_train_scaled = (X_train - X_train.mean()) / X_train.std()\n",
    "    X_test_scaled = (X_test - X_train.mean()) / X_train.std()\n",
    "\n",
    "\n",
    "\n",
    "    return X_train_scaled.values, y_train.values, X_test_scaled.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    \"\"\" Perform k-fold cross-validation \"\"\"\n",
    "    # Convert X and y to NumPy arrays if they are not already\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Check if X and y have the same length\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(\"X and y must have the same length\")\n",
    "\n",
    "    fold_size = len(X) // n_splits\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)  # Shuffle the indices\n",
    "    scores = []\n",
    "\n",
    "    for fold in range(n_splits):\n",
    "        # Calculate the indices for validation set\n",
    "        val_indices = indices[fold * fold_size : (fold + 1) * fold_size] if fold < n_splits - 1 else indices[fold * fold_size :]\n",
    "\n",
    "        train_indices = np.concatenate([indices[:fold * fold_size], indices[(fold + 1) * fold_size:]])\n",
    "        \n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "        # Fit the model and predict\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_val_pred = knn.predictTrain(X_val)\n",
    "        \n",
    "        # Calculate accuracy or any other metric\n",
    "        score = np.mean(y_val_pred == y_val)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:12 0.8780666666666667\n",
      "Cross-validation scores:13 0.8807333333333334\n"
     ]
    }
   ],
   "source": [
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "for k in range(12,14):\n",
    "    knn = KNN(k, distance_metric='euclidean')\n",
    "    cv_scores = cross_validate(X, y, knn)\n",
    "    avg_cv = np.mean(cv_scores)\n",
    "    print(\"Cross-validation scores:\" + str(k) + \" \" + str(avg_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.88166667 0.88066667 0.876      0.87966667 0.88266667]\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "# Create and evaluate model\n",
    "\n",
    "\n",
    "knn = KNN(k=13, distance_metric='euclidean')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_validate(X, y, knn)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# TODO: hyperparamters tuning\n",
    "\n",
    "\n",
    "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
    "knn.fit(X, y)\n",
    "test_predictions = knn.predictTest(X_test)\n",
    "\n",
    "# Save test predictions\n",
    "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
